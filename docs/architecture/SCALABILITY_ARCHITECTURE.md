# IP2A Database Scalability Architecture
## Multi-User Environment: 4000 Concurrent Users + 40 Staff

---

## Requirements Analysis

### User Types & Access Patterns

| User Type | Count | Access Level | Usage Pattern | Peak Load |
|-----------|-------|--------------|---------------|-----------|
| **Staff Users** | 40 | Admin (R/W) | Heavy writes, complex queries | 40 concurrent |
| **Union Members** | 4,000 | Read-only/Limited Write | View profile, update info | 4,000 concurrent |
| **Public Access** | Variable | Read-only | View public info | 1,000 concurrent |
| **API Integrations** | 5-10 | R/W | Automated operations | 50 req/s |

**Total Capacity Required:**
- **Peak Concurrent Users:** 5,040
- **Peak Requests/Second:** 1,000-2,000 RPS
- **Database Connections Needed:** 100-200 (with pooling)
- **Read:Write Ratio:** 90:10 (typical for member portals)

---

## Current Implementation Issues âŒ

### 1. No Connection Pooling
**Current:** Each request creates a new database connection
```python
# src/db/session.py - CURRENT (NOT SCALABLE)
def get_db():
    db = SessionLocal()  # Creates new connection every time
    try:
        yield db
    finally:
        db.close()
```

**Problem:**
- PostgreSQL max_connections default: 100
- Each web worker needs 10-20 connections
- 4000 users = 4000 connections = **CRASH** âŒ

### 2. No Read Replicas
- All reads and writes hit primary database
- No horizontal scaling for read-heavy workload
- Single point of failure

### 3. No Caching Layer
- Every profile view = database query
- Repeated queries waste resources
- No protection against query storms

### 4. No Rate Limiting
- Vulnerable to abuse (someone can spam API)
- No protection against DDoS
- No per-user throttling

### 5. No Session Management
- No JWT authentication system
- No role-based access control (RBAC)
- No API key management

---

## Recommended Architecture

```
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   CloudFlare    â”‚
                           â”‚   CDN + DDoS    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Load Balancer  â”‚
                           â”‚   (AWS ALB)     â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚  FastAPI    â”‚ â”‚  FastAPI    â”‚ â”‚  FastAPI   â”‚
            â”‚  Instance 1 â”‚ â”‚  Instance 2 â”‚ â”‚  Instance Nâ”‚
            â”‚  (Docker)   â”‚ â”‚  (Docker)   â”‚ â”‚  (Docker)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                   â”‚               â”‚               â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Connection     â”‚
                          â”‚  Pooler         â”‚
                          â”‚  (PgBouncer)    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚  PostgreSQL  â”‚ â”‚   Read   â”‚ â”‚   Read     â”‚
            â”‚   Primary    â”‚ â”‚ Replica 1â”‚ â”‚ Replica 2  â”‚
            â”‚   (Write)    â”‚ â”‚  (Read)  â”‚ â”‚  (Read)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚    Redis    â”‚
            â”‚   Cache +   â”‚
            â”‚   Sessions  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Plan

### Phase 1: Connection Pooling (CRITICAL - Week 1)

#### 1.1 PgBouncer Setup

**Install PgBouncer:**
```bash
# Docker Compose addition
services:
  pgbouncer:
    image: pgbouncer/pgbouncer:latest
    environment:
      - DATABASES_HOST=postgres
      - DATABASES_PORT=5432
      - DATABASES_USER=postgres
      - DATABASES_PASSWORD=${POSTGRES_PASSWORD}
      - DATABASES_DBNAME=ip2a
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=10000
      - DEFAULT_POOL_SIZE=25
      - RESERVE_POOL_SIZE=5
    ports:
      - "6432:6432"
    depends_on:
      - postgres
```

**Benefits:**
- âœ… Supports 10,000 client connections
- âœ… Only uses 25 database connections
- âœ… 400:1 connection multiplexing ratio
- âœ… Minimal latency overhead (<1ms)

#### 1.2 SQLAlchemy Connection Pool Configuration

```python
# src/db/session.py - UPDATED

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
from src.config.settings import settings

# Connection pool configuration
engine = create_engine(
    settings.DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,              # Connections per worker
    max_overflow=10,           # Extra connections under load
    pool_pre_ping=True,        # Verify connection before use
    pool_recycle=3600,         # Recycle connections after 1 hour
    pool_timeout=30,           # Wait 30s for connection
    echo=False,                # Disable SQL logging in production
    connect_args={
        "application_name": "ip2a_api",
        "connect_timeout": 10,
        "options": "-c statement_timeout=30000"  # 30s query timeout
    }
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db():
    """Get database session with connection pooling."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()  # Returns connection to pool
```

**Capacity:**
- 10 FastAPI workers Ã— 20 connections = 200 total connections
- PgBouncer multiplexes 10,000 clients â†’ 25 DB connections
- **Result:** Can handle 4,000+ concurrent users âœ…

---

### Phase 2: Read Replicas (Week 2)

#### 2.1 PostgreSQL Replication Setup

**Primary Database (Write):**
```bash
# postgresql.conf
wal_level = replica
max_wal_senders = 5
max_replication_slots = 5
synchronous_commit = off  # Async for performance
```

**Read Replica (Read-Only):**
```bash
# Setup replication
pg_basebackup -h primary -D /var/lib/postgresql/data -U replicator -v -P
```

#### 2.2 Read/Write Splitting

```python
# src/db/session.py - READ/WRITE SPLIT

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Primary database (writes)
write_engine = create_engine(
    settings.DATABASE_WRITE_URL,  # Primary
    pool_size=20,
    max_overflow=10,
)

# Read replica (reads)
read_engine = create_engine(
    settings.DATABASE_READ_URL,  # Replica
    pool_size=30,  # More connections for reads
    max_overflow=20,
)

WriteSession = sessionmaker(bind=write_engine)
ReadSession = sessionmaker(bind=read_engine)

def get_db_write():
    """Get write database session (primary)."""
    db = WriteSession()
    try:
        yield db
    finally:
        db.close()

def get_db_read():
    """Get read database session (replica)."""
    db = ReadSession()
    try:
        yield db
    finally:
        db.close()

# Convenience function for read-heavy endpoints
def get_db():
    """Default to read replica for most endpoints."""
    return get_db_read()
```

**Usage in Routers:**
```python
# Read-only endpoints (90% of traffic)
@router.get("/members/{id}")
def read_member(id: int, db: Session = Depends(get_db_read)):
    return get_member(db, id)

# Write endpoints (10% of traffic)
@router.post("/members/")
def create_member(data: MemberCreate, db: Session = Depends(get_db_write)):
    return create_member(db, data)
```

**Capacity Increase:**
- 2 read replicas = 3x read capacity
- Can add more replicas as needed
- **Result:** Handles 90% of traffic without hitting primary âœ…

---

### Phase 3: Caching Layer (Week 3)

#### 3.1 Redis Cache Setup

```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
```

#### 3.2 Caching Implementation

```python
# src/cache/redis_cache.py

import redis
import json
from typing import Optional, Any
from functools import wraps

redis_client = redis.Redis(
    host='redis',
    port=6379,
    db=0,
    decode_responses=True
)

def cache_result(ttl: int = 300):
    """
    Decorator to cache function results in Redis.

    Args:
        ttl: Time to live in seconds (default: 5 minutes)
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Generate cache key
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"

            # Check cache
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # Call function
            result = func(*args, **kwargs)

            # Store in cache
            redis_client.setex(
                cache_key,
                ttl,
                json.dumps(result, default=str)
            )

            return result
        return wrapper
    return decorator

# Usage example
@cache_result(ttl=300)  # Cache for 5 minutes
def get_member_profile(db, member_id: int):
    """Get member profile (cached)."""
    return db.query(Member).filter(Member.id == member_id).first()
```

**What to Cache:**
| Data Type | TTL | Invalidation |
|-----------|-----|--------------|
| Member profiles | 5 min | On update |
| Organization lists | 10 min | On create/update |
| Static content | 1 hour | Manual |
| Session data | 24 hours | On logout |
| Rate limit counters | 1 min | Automatic |

**Capacity Increase:**
- 80-90% of reads served from cache
- <1ms latency vs 10-50ms database
- **Result:** 10x read performance improvement âœ…

---

### Phase 4: Authentication & Authorization (Week 4)

#### 4.1 JWT Authentication

```python
# src/auth/jwt.py

from datetime import datetime, timedelta
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

SECRET_KEY = "your-secret-key-here"  # Use env var in production
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30
REFRESH_TOKEN_EXPIRE_DAYS = 7

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
security = HTTPBearer()

def create_access_token(data: dict) -> str:
    """Create JWT access token."""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire, "type": "access"})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def create_refresh_token(data: dict) -> str:
    """Create JWT refresh token."""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(days=REFRESH_TOKEN_EXPIRE_DAYS)
    to_encode.update({"exp": expire, "type": "refresh"})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)) -> dict:
    """Verify JWT token and return payload."""
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )

def get_current_user(payload: dict = Depends(verify_token)) -> str:
    """Get current user from JWT token."""
    user_id = payload.get("sub")
    if user_id is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid token payload"
        )
    return user_id
```

#### 4.2 Role-Based Access Control (RBAC)

```python
# src/auth/rbac.py

from enum import Enum
from fastapi import Depends, HTTPException, status

class Role(str, Enum):
    ADMIN = "admin"
    STAFF = "staff"
    MEMBER = "member"
    PUBLIC = "public"

class Permission(str, Enum):
    # Member permissions
    MEMBER_READ_OWN = "member:read:own"
    MEMBER_UPDATE_OWN = "member:update:own"

    # Staff permissions
    MEMBER_READ_ALL = "member:read:all"
    MEMBER_UPDATE_ALL = "member:update:all"
    MEMBER_CREATE = "member:create"

    # Admin permissions
    MEMBER_DELETE = "member:delete"
    SYSTEM_ADMIN = "system:admin"

ROLE_PERMISSIONS = {
    Role.PUBLIC: [],
    Role.MEMBER: [
        Permission.MEMBER_READ_OWN,
        Permission.MEMBER_UPDATE_OWN,
    ],
    Role.STAFF: [
        Permission.MEMBER_READ_OWN,
        Permission.MEMBER_UPDATE_OWN,
        Permission.MEMBER_READ_ALL,
        Permission.MEMBER_UPDATE_ALL,
        Permission.MEMBER_CREATE,
    ],
    Role.ADMIN: [
        # All permissions
        *Permission.__members__.values()
    ],
}

def require_permission(permission: Permission):
    """Decorator to require specific permission."""
    def decorator(payload: dict = Depends(verify_token)):
        user_role = Role(payload.get("role", "public"))
        user_permissions = ROLE_PERMISSIONS.get(user_role, [])

        if permission not in user_permissions:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail=f"Permission denied: {permission}"
            )

        return payload
    return decorator

# Usage in routers
@router.get("/members/{id}")
def read_member(
    id: int,
    db: Session = Depends(get_db_read),
    user: dict = Depends(require_permission(Permission.MEMBER_READ_ALL))
):
    """Read member profile (requires MEMBER_READ_ALL permission)."""
    return get_member(db, id)

@router.put("/members/{id}")
def update_member(
    id: int,
    data: MemberUpdate,
    db: Session = Depends(get_db_write),
    user: dict = Depends(require_permission(Permission.MEMBER_UPDATE_ALL))
):
    """Update member (requires MEMBER_UPDATE_ALL permission)."""
    return update_member(db, id, data)
```

---

### Phase 5: Rate Limiting (Week 5)

```python
# src/middleware/rate_limit.py

from fastapi import Request, HTTPException, status
from starlette.middleware.base import BaseHTTPMiddleware
import redis
import time

redis_client = redis.Redis(host='redis', port=6379, db=1)

class RateLimitMiddleware(BaseHTTPMiddleware):
    """Rate limiting middleware using Redis."""

    def __init__(self, app, requests_per_minute: int = 60):
        super().__init__(app)
        self.requests_per_minute = requests_per_minute

    async def dispatch(self, request: Request, call_next):
        # Get client identifier (IP or user ID)
        client_id = request.headers.get("x-user-id") or request.client.host

        # Rate limit key
        key = f"rate_limit:{client_id}:{int(time.time() // 60)}"

        # Increment counter
        current = redis_client.incr(key)

        # Set expiry on first request
        if current == 1:
            redis_client.expire(key, 60)

        # Check limit
        if current > self.requests_per_minute:
            raise HTTPException(
                status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                detail=f"Rate limit exceeded: {self.requests_per_minute} requests per minute"
            )

        # Add rate limit headers
        response = await call_next(request)
        response.headers["X-RateLimit-Limit"] = str(self.requests_per_minute)
        response.headers["X-RateLimit-Remaining"] = str(self.requests_per_minute - current)

        return response

# Register middleware
app.add_middleware(RateLimitMiddleware, requests_per_minute=60)
```

**Rate Limits by User Type:**
| User Type | Requests/Minute | Requests/Hour |
|-----------|-----------------|---------------|
| Public | 10 | 100 |
| Member | 60 | 1,000 |
| Staff | 300 | 10,000 |
| Admin | 1,000 | 50,000 |
| API Key | 1,000 | 100,000 |

---

## Performance Benchmarks & Capacity

### Without Optimizations (Current)
| Metric | Value |
|--------|-------|
| Max Concurrent Users | ~50 |
| Requests/Second | ~100 |
| Avg Response Time | 50-200ms |
| P95 Response Time | 500ms |
| Database Connections | 1 per request |
| Cache Hit Rate | 0% |
| **Result** | âŒ Cannot handle 4,000 users |

### With All Optimizations (Proposed)
| Metric | Value |
|--------|-------|
| Max Concurrent Users | **10,000+** |
| Requests/Second | **5,000+** |
| Avg Response Time | 10-50ms |
| P95 Response Time | 100ms |
| Database Connections | 200 pooled |
| Cache Hit Rate | 80-90% |
| **Result** | âœ… Can handle 4,000 users easily |

---

## Cost Estimates (AWS)

### Minimum Production Setup
| Component | Instance Type | Monthly Cost |
|-----------|---------------|--------------|
| Load Balancer | ALB | $20 |
| FastAPI (3 instances) | t3.medium | $90 |
| PostgreSQL Primary | db.t3.large | $120 |
| Read Replica (2) | db.t3.medium | $140 |
| PgBouncer | Included | $0 |
| Redis Cache | cache.t3.small | $40 |
| CloudFlare | Free tier | $0 |
| **Total** | | **~$410/month** |

### High Performance Setup
| Component | Instance Type | Monthly Cost |
|-----------|---------------|--------------|
| Load Balancer | ALB | $20 |
| FastAPI (5 instances) | t3.large | $250 |
| PostgreSQL Primary | db.r5.xlarge | $350 |
| Read Replica (3) | db.r5.large | $525 |
| PgBouncer | t3.small | $15 |
| Redis Cache | cache.r5.large | $180 |
| CloudFlare | Pro | $20 |
| **Total** | | **~$1,360/month** |

---

## Implementation Timeline

| Phase | Duration | Effort | Priority |
|-------|----------|--------|----------|
| **Phase 1: Connection Pooling** | 1 week | 8-12 hours | ğŸ”´ CRITICAL |
| **Phase 2: Read Replicas** | 1 week | 12-16 hours | ğŸŸ  HIGH |
| **Phase 3: Caching** | 1 week | 16-20 hours | ğŸŸ  HIGH |
| **Phase 4: Auth/RBAC** | 2 weeks | 30-40 hours | ğŸŸ¡ MEDIUM |
| **Phase 5: Rate Limiting** | 1 week | 8-12 hours | ğŸŸ¡ MEDIUM |
| **Phase 6: Monitoring** | 1 week | 12-16 hours | ğŸŸ¢ LOW |
| **Total** | **7 weeks** | **~100 hours** | |

---

## Monitoring & Alerts

```python
# Key metrics to monitor
CRITICAL_ALERTS = {
    "db_connections_used": "> 180 of 200",
    "response_time_p95": "> 500ms",
    "error_rate": "> 1%",
    "cache_hit_rate": "< 70%",
    "cpu_usage": "> 80%",
}

WARNING_ALERTS = {
    "db_connections_used": "> 150 of 200",
    "response_time_p95": "> 200ms",
    "cache_hit_rate": "< 80%",
    "disk_usage": "> 75%",
}
```

---

## Security Checklist

- [ ] Enable SSL/TLS for all connections
- [ ] Use environment variables for secrets
- [ ] Enable row-level security (RLS) in PostgreSQL
- [ ] Implement JWT token rotation
- [ ] Add API key authentication for integrations
- [ ] Enable CloudFlare DDoS protection
- [ ] Set up Web Application Firewall (WAF)
- [ ] Implement IP whitelisting for admin access
- [ ] Enable audit logging for all data access
- [ ] Regular security audits and penetration testing

---

## Next Steps

### Immediate (This Week)
1. âœ… Review this architecture document
2. âš ï¸ Implement connection pooling (PgBouncer + SQLAlchemy)
3. âš ï¸ Add basic health check endpoint
4. âš ï¸ Set up monitoring (Prometheus + Grafana)

### Short-term (2-4 Weeks)
1. Set up read replicas
2. Implement Redis caching
3. Add JWT authentication
4. Implement RBAC

### Medium-term (1-2 Months)
1. Load testing with 4,000 concurrent users
2. Performance tuning based on results
3. Set up production infrastructure
4. Deploy to staging environment

### Long-term (3+ Months)
1. Auto-scaling configuration
2. Disaster recovery testing
3. Security audit
4. Production launch

---

**Last Updated:** 2026-01-27
**Version:** 1.0
**Owner:** IP2A Database Team
